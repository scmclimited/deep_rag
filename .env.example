# =============================================================================
# Deep RAG Backend - Environment Configuration
# =============================================================================
# This file contains environment variables specific to the Backend API service.
# The backend provides FastAPI endpoints for document ingestion and querying.
#
# Copy this file to .env and fill in your values:
#   cp .env.example .env
# =============================================================================

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# Database connection settings for PostgreSQL with pgvector extension.
# The backend connects to the database to store and retrieve document embeddings.

DB_HOST=localhost
DB_PORT=5432
DB_USER=deep_rag_user
DB_PASS=deep_rag_password
DB_NAME=deep_rag_db

# =============================================================================
# LLM CONFIGURATION
# =============================================================================
# Language Model provider settings for agentic reasoning and query processing.

# LLM Provider (currently supports: gemini, openai, ollama)
LLM_PROVIDER=gemini

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here

# Gemini Model Selection
# Recommended models:
#   - gemini-1.5-flash (RECOMMENDED) - 1M token context, fast, excellent reasoning
#   - gemini-2.0-flash (LATEST) - 1M token context, improved performance
#   - gemini-2.5-flash-lite (LIGHTWEIGHT) - Limited context, very fast
GEMINI_MODEL=gemini-2.5-flash-lite

# LLM Temperature (0.0 = deterministic, 1.0 = creative)
# Lower values (0.1-0.3) are recommended for RAG applications
LLM_TEMPERATURE=0.2

# =============================================================================
# EMBEDDING CONFIGURATION
# =============================================================================
# Multi-modal embedding model settings for document and image embeddings.

# CLIP Model Selection
#   - sentence-transformers/clip-ViT-L-14 (RECOMMENDED) - 768 dimensions, better quality
#   - sentence-transformers/clip-ViT-B-32 - 512 dimensions, faster performance
CLIP_MODEL=sentence-transformers/clip-ViT-L-14

# Embedding Dimensions (must match CLIP model)
#   - 768 for CLIP-ViT-L-14
#   - 512 for CLIP-ViT-B-32
EMBEDDING_DIM=768

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================

# Run tests on backend startup
# Set to true to run database schema tests when backend container starts
RUN_TESTS_ON_STARTUP=false
AUTOMATE_ENDPOINT_RUNS_ON_BOOT=false


# Confidence scoring thresholds
CONF_W0=-0.5          # Bias (less negative = higher base)
CONF_W1=2.2           # max_rerank (reduced from 3.0)
CONF_W2=1.0           # margin (reduced from 1.5)
CONF_W3=1.6           # mean_cosine (reduced from 2.0)
CONF_W4=-0.5          # cosine_std (more negative)
CONF_W5=0.8           # cos_coverage (reduced from 1.0)
CONF_W6=1.2           # bm25_norm (reduced from 1.5)
CONF_W7=0.8           # term_coverage (reduced from 1.2)
CONF_W8=0.6           # unique_page_frac (reduced from 0.8)
CONF_W9=0.6           # doc_diversity (increased from 0.4)
CONF_W10=1.0          # answer_overlap (reduced from 1.2)

# Decision thresholds
CONF_ABSTAIN_TH=0.30  # 30%
CONF_CLARIFY_TH=0.55  # 55%